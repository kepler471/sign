{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
      },
      "cell_type": "markdown",
      "source": "# ASL sign challenge exploration\n\n[Model](## Building the model using Keras)\n\nData includes 3000 images per sign in ASL"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nfrom PIL import Image\nfrom IPython.display import clear_output\nfrom skimage.transform import resize\n%matplotlib inline\n\n# kaggle input data path (change when running a local notebook)\nTRAIN_DIR = \"../input/asl_alphabet_train/asl_alphabet_train/\"\n\n# Sort signs A through Z then del, nothing, space\nclass_folders = np.sort(os.listdir(TRAIN_DIR))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ccf88376de49e4b72e8837aa99480e49b3b2e2b"
      },
      "cell_type": "code",
      "source": "''' initialising values for model building. these will be tested with alterations\n    to try and optimise the model  '''\n\n# limiting data for prototyping model\ncutoff = 500\n\n# validation farction\nval_frac = 0.1\n\n# model parameters\nbatch_size = 100\nepochs = 10\nfilters = 16\ndropouts = .25\nlearning_rate = 0.005\nkernel_size = [(3,3), (3,3), (3,3)]\n\n# keras model checkpoint file\nrun_name = str(epochs)+'epochs_'+str(learning_rate)+'LR.ckpt'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load in data to numpy array, slow on cpu, memory fill?\n### Change this from a loop? Could use DataFrame\n\nlabels = []\ndata = []\n\nlabel_no = 0\nfor class_name in class_folders:\n    clear_output()\n    \n    label_dir = TRAIN_DIR + class_name + \"/\"\n    class_files = os.listdir(label_dir)\n    for i,file in enumerate(class_files):\n        \n        # print(\"On class {} and file {}\".format(label_no, i))\n        img = np.array(Image.open(label_dir + file))\n        \n        # removing the blue border on all images\n        trim_img = img[15:-10,15:-10]\n        \n        # Downsizing images to 64x64\n        data.append(resize(trim_img, (64,64)))\n        labels.append(label_no)\n        \n        # Cutoff samples for each sign to speed testing\n        if i > cutoff:\n            break\n    label_no += 1\n    \n    \ndata = np.array(data)\nlabels = np.array(labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-output": false,
        "trusted": true,
        "_uuid": "2cf51ab03807a550c60ac73c7f97eb7af70d5af6"
      },
      "cell_type": "code",
      "source": "print(np.shape(data))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "00a1cde56dc977cbd26cd2444a24ed789a8232db",
        "trusted": true,
        "_kg_hide-input": false,
        "_kg_hide-output": false
      },
      "cell_type": "code",
      "source": "# checking what the formatted data looks like\nimport matplotlib.pyplot as plt\nfrom skimage.transform import resize\n\nfig=plt.figure(figsize=(18, 18), dpi= 80, facecolor='w', edgecolor='k')\nrows = 5\ncolumns = 6\nfor i in range(1,30):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(resize(data[i*cutoff,:,:,:], (64,64)))\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e936866649e2594bf9e883cae249b4c63137cf9b"
      },
      "cell_type": "markdown",
      "source": "## Data Augmentation"
    },
    {
      "metadata": {
        "_uuid": "bc8d0cb119905006c05edfc74b04a4b2bd50df3d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c172acd9a7f6a116fff577af0fae8a6eb8fef91d"
      },
      "cell_type": "markdown",
      "source": "Might be low res but will run better for a first passthrough. Blue borders are removed."
    },
    {
      "metadata": {
        "_uuid": "f971a76b80954e42a0f1b8f9351b838fb687ff47",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\n\n# Take a portion of data for validation\nX_train, X_val, Y_train, Y_val = train_test_split(data, \n                          labels, test_size=0.1, random_state=4)\n\nY_train = np_utils.to_categorical(Y_train)\nY_val = np_utils.to_categorical(Y_val)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0bebd03fda2ec542be3a4cd292748061f8c5c384"
      },
      "cell_type": "markdown",
      "source": "## Building the model using Keras\n\n### Network\n\nThe network consists of two main components :\n\n#### Convolutional layers : \n\nthe convolutional layer is responsible for the convolutional operation in which feature maps identifies features in the images. and is usually followed by two types of layers which are :\n\n   Dropout : Dropout is a regulization technique where you turn off part of the network's layers randomally to increase regulization and hense decrease overfitting. We use when the training set accuracy is muuch higher than the test set accuracy.\n    Max Pooling : The maximum output in a rectangular neighbourhood. It is used to make the network more flexible to slight changes and decrease the network computationl expenses by extracting the group of pixels that are highly contributing to each feature in the feature maps in the layer.\n\n#### Dense layers : \n\nThe dense layer is a fully connected layer that comes after the convolutional layers and they give us the output vector of the Network.\n    \n[Number of parameteres for convolution layers?](https://datascience.stackexchange.com/questions/17064/number-of-parameters-for-convolution-layers)\n\n### Compilation\nBefore training a model, you need to configure the learning process, which is done via the  `compile` method, receiving 3 arguments: `optimizer`, `loss function`,  `list of metrics`. \n\n[Keras Docs: Compilation](https://keras.io/getting-started/sequential-model-guide/#compilation)\n\n[Overview of gradient descent algorithms](http://ruder.io/optimizing-gradient-descent/)\n\nAdam is a method for Stochastic Optimization. See the following papers: \n\n[Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n\n[On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n\nCost function : \nIt is a measure of the overall loss in our network after assigning values to the parameters during the forward phase so it indicates how well the parameters were chosen during the forward probagation phase.\n\nOptimizer : \nIt is the gradiant descent algorithm that is used. We use it to minimize the cost function to approach the minimum point. We are using adam optimizer which is one of the best gradient descent algorithms."
    },
    {
      "metadata": {
        "_uuid": "33eb1f3d75a2126b13a36e085150a24852636c04",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\n\n# Build a model using 2D Convolution\ndef training(weights_path):\n    model = Sequential()\n    \n    #layers\n    model.add(Conv2D(filters = filters, kernel_size = kernel_size[0], padding = 'Same', \n                    activation = 'relu', input_shape = (64,64,3)))\n    model.add(Conv2D(filters = filters, kernel_size = kernel_size[0], padding = 'Same', \n                    activation = 'relu'))\n\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters = 2*filters, kernel_size = kernel_size[1], padding = 'Same',\n                    activation = 'relu'))\n    model.add(Conv2D(filters = 2*filters, kernel_size = kernel_size[1], padding = 'Same',\n                    activation = 'relu'))\n    \n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters = 4*filters, kernel_size = kernel_size[2], padding = 'Same',\n                    activation = 'relu'))\n    model.add(Conv2D(filters = 4*filters, kernel_size = kernel_size[2], padding = 'Same',\n                    activation = 'relu'))\n    \n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(dropouts))\n    \n    model.add(Flatten())\n    model.add(Dense(8*filters, activation = 'relu'))\n    model.add(Dropout(dropouts))\n    model.add(Dense(label_no, activation = 'softmax'))\n    \n    optimizer = Adam(lr=learning_rate)\n    model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', \n                    metrics = ['accuracy'])\n    \n    #if os.path.isfile(weights_path):\n    #    model.load_weights(weights_path)\n    \n    return model\n\nmodel = training(None)\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad0b97d70a39ad8bed9d6a2ec8f6d9c6c76deedb"
      },
      "cell_type": "code",
      "source": "saver = ModelCheckpoint(run_name, monitor=\"val_loss\")\n\nhistory = model.fit(X_train, Y_train, batch_size = batch_size, \n                    epochs = epochs, validation_data = (X_val, Y_val),\n                    verbose = 2, callbacks = [saver])\n\n#history = model.fit_generator()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f7973af74b4ae9a623961267deff75e21810057"
      },
      "cell_type": "code",
      "source": "import itertools\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \nfig=plt.figure(figsize=(15, 15))\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(29))\nplt.savefig(run_name[:-5]+'_conf.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "51de9ea62165f5c8ad4de8f8023f4d857fcd7272"
      },
      "cell_type": "code",
      "source": "test42 = model.predict(X_val[10:11,:,:,:])\n#plt.plot(np.arange(label_no),test42)\n#plt.figure()\n#plt.imshow(X_val[10,:,:,:])\n# finding the error, are our X_vals still good? = True\n(Y_val[10])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79a8b62b178e99757e395e0a3ce2bea6231e227a"
      },
      "cell_type": "code",
      "source": "plt.figure()\nplt.imshow(X_val[10,:,:,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61f526ffddba37d990630cb523bad2439312ca04"
      },
      "cell_type": "code",
      "source": "import seaborn as sns\ny_val = [np.argmax(one_hot) for one_hot in Y_val]\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\nsns.distplot(y_val, kde=False, rug=True, bins=29)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ccfb0871c0557b8d4a04308720bc668dcf5bc5ba"
      },
      "cell_type": "code",
      "source": "history.history.keys()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e2f777de3f309ea4c35d4fab9fb08e58adfe99d"
      },
      "cell_type": "code",
      "source": "plt.figure()\nfor keys in ['val_loss', 'loss']:\n    plt.plot(np.arange(0,10), history.history[keys], label=keys)\nplt.legend()\n\nplt.figure()\nfor keys in ['val_acc', 'acc']:\n    plt.plot(np.arange(0,10), history.history[keys], label=keys)\nplt.legend()\nplt.title(max(history.history['val_acc']))\nplt.savefig(run_name[:-5]+'_acc.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab818b9608ded0191ef9e7be6a4f7873c90900f2"
      },
      "cell_type": "code",
      "source": "history.history['val_acc']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b18341e3b0f3cb669cb217a47919f5db26ba0dde"
      },
      "cell_type": "markdown",
      "source": "# View false positives\n\nLets have a look at where the network hasn't performed well, it may point towards flaws in the method/model architecture or flaws with the data such as poor lighting. \n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb9bc7d2ceb7038cd0c37e60e03c58f79664f375"
      },
      "cell_type": "code",
      "source": "# Predict all images n the training set\ntrain_pred = model.predict(X_train)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "102468a6bf5a9fc00088bbe3cdfdba49bab88ba9"
      },
      "cell_type": "markdown",
      "source": "# Analyse Results"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "80eb55aecc336cd3c7ce0b87560b8f0c36ec1350"
      },
      "cell_type": "markdown",
      "source": "Lets have a look at the model training curves to see if we have set the hyperparameters corectly"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e76f74e377e4a4df765fac42e52424dfc1a3da61"
      },
      "cell_type": "code",
      "source": "from keras import metrics",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}